import os
import logging
from dotenv import load_dotenv
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_groq import ChatGroq

from app.config import load_params

params = load_params('params.yaml')
chatbot_params = params['chatbot']

log_dir_path = chatbot_params['log_dir_path']
chatbot_log_file_path = chatbot_params['chatbot_log_file_path']

# Ensure logging directory exists
os.makedirs(log_dir_path, exist_ok=True)

# Logger setup
logger = logging.getLogger("Chatbot")
logger.setLevel(logging.DEBUG)

console_handler = logging.StreamHandler()
console_handler.setLevel(logging.DEBUG)

file_path = os.path.join(log_dir_path, chatbot_log_file_path)
file_handler = logging.FileHandler(file_path)
file_handler.setLevel(logging.DEBUG)

formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
console_handler.setFormatter(formatter)
file_handler.setFormatter(formatter)

# Prevent duplicate handlers
if not logger.handlers:
    logger.addHandler(console_handler)
    logger.addHandler(file_handler)

# Load environment variables
load_dotenv(override=True)
groq_api_key = os.getenv("GROQ_API_KEY")

# Prompt setup
prompt_template = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful assistant who answers user queries accurately and politely."),
    ("user", "Question: {input}")
])
output_parser = StrOutputParser()

def generate_response(llm: str, question: str) -> str:
    """
    Generate a response to a user question using the specified language model.

    Args:
        llm (str): The name of the LLM model to use (e.g., "llama-3.1-8b-instant").
        question (str): The user's input question to be answered.

    Returns:
        str: The text response generated by the language model.

    Raises:
        ValueError: If the question is empty or None.
        KeyError: If configuration keys are missing.
        RuntimeError: If the model fails to generate a response.
    """
    try:
        if not question or not question.strip():
            logger.warning("Empty question provided.")
            raise ValueError("Question cannot be empty.")

        logger.info("Initializing chatbot with model: %s", llm)

        llm_model = ChatGroq(model=llm, api_key=groq_api_key)
        chain = prompt_template | llm_model | output_parser

        logger.debug("Invoking LLM for response...")
        response = chain.invoke({"input": question})

        logger.info("Chatbot response successfully generated.")
        return response

    except ValueError as ve:
        logger.error("Invalid input: %s", ve, exc_info=True)
        raise

    except KeyError as ke:
        logger.error("Missing key in configuration or model params: %s", ke, exc_info=True)
        raise

    except Exception as e:
        logger.exception("Unexpected error while generating LLM response: %s", str(e))
        raise RuntimeError(f"Chatbot failed to generate response: {e}") from e