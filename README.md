# ğŸ¤– End-to-End LLM Chatbot (MongoDB + FastAPI + Streamlit)

A full-stack, production-ready conversational AI chatbot powered by Google Gemini LLM. Built with FastAPI, LangChain, and Streamlit, this project features a MongoDB backend for persistent chat history, automated CI/CD with GitHub Actions, and cloud deployment (AWS ECS for backend, Render for frontend).

<div align="center">

â­ **Star this repo if it helped you build your own LLM chatbot!** â­

</div>

---

## ğŸ“‹ Table of Contents

- [âœ¨ Features](#-features)
- [ğŸ—ï¸ Architecture](#-architecture)
- [ğŸ› ï¸ Tech Stack](#-tech-stack)
- [ğŸ“ Project Structure](#-project-structure)
- [ğŸš€ Getting Started (Local)](#-getting-started-local)
- [ğŸ³ Backend Deployment (AWS ECS)](#-backend-deployment-aws-ecs)
- [ğŸŒ Frontend Deployment (Render)](#-frontend-deployment-render)
- [ğŸ”„ CI/CD (GitHub Actions)](#-cicd-github-actions)
- [ğŸ“š API Documentation](#-api-documentation)
- [âš™ï¸ Configuration Reference](#-configuration-reference)
- [ğŸ§  Example Prompt Flow](#-example-prompt-flow)
- [ğŸ‘¨â€ğŸ’» Author](#-author)
- [ğŸ“Š Project Status](#-project-status)
- [ğŸ“œ License](#-license)

---

## âœ¨ Features

- âœ… **FastAPI Backend (Async)** â€“ High-performance, production-grade REST API
- ğŸ’¬ **Streamlit Frontend (Render)** â€“ Clean, interactive chat interface
- ğŸ§  **Google Gemini Integration** â€“ LLM-powered intelligent responses via LangChain
- ğŸ—„ï¸ **MongoDB Storage** â€“ Session-based chat memory persistence
- ğŸ³ **Dockerized Architecture** â€“ Fully containerized for portability
- â˜ï¸ **AWS ECS (Fargate)** â€“ Scalable, serverless backend hosting
- ğŸ” **Secure Config via SSM** â€“ AWS Parameter Store for environment secrets
- ğŸ” **GitHub Actions CI/CD** â€“ Automated deployment pipeline
- ğŸ“œ **Structured Logging** â€“ AWS CloudWatch + Rotating file logs

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Streamlit UI   â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚  FastAPI Backend â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚   MongoDB     â”‚
â”‚ (Render Cloud) â”‚       â”‚   (AWS ECS)      â”‚       â”‚   (Atlas)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚ Google     â”‚
                         â”‚ Gemini LLM â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|-----------|
| **Frontend** | Streamlit (Render Cloud) |
| **Backend** | FastAPI, Uvicorn |
| **Database** | MongoDB Atlas |
| **LLM** | Google Gemini (LangChain Integration) |
| **Cloud Backend** | AWS ECS (Fargate) |
| **Containerization** | Docker |
| **CI/CD** | GitHub Actions |
| **Secrets** | AWS Systems Manager (Parameter Store) |
| **Monitoring** | AWS CloudWatch |

---

## ğŸ“ Project Structure

```
END-TO-END-LLM-CHATBOT/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ deploy.yaml              # CI/CD pipeline
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ fastapi_app.py          # FastAPI entry point
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py               # Configuration loader
â”‚   â”‚   â”œâ”€â”€ exception.py            # Custom exceptions
â”‚   â”‚   â””â”€â”€ logger.py               # Logging setup
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ mango_database.py       # MongoDB async integration
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ chatbot.py              # Chatbot logic (LangChain + Gemini)
â”‚   â”‚   â”œâ”€â”€ smoke_test_chat.py      # Smoke tests
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â””â”€â”€ tests/
â”‚       â”œâ”€â”€ __pycache__/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ smoke_test_chat.py      # Test suite
â”œâ”€â”€ config/
â”‚   â””â”€â”€ params.yaml                 # Application parameters
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ chatbot_app.py              # Streamlit frontend
â”œâ”€â”€ .dockerignore                   # Docker ignore rules
â”œâ”€â”€ .env                            # Environment variables (local)
â”œâ”€â”€ .env.example                    # Example environment variables
â”œâ”€â”€ .gitignore                      # Git ignore rules
â”œâ”€â”€ .python-version                 # Python version specification
â”œâ”€â”€ dockerfile                      # Docker image definition
â”œâ”€â”€ ecs-task-def.json               # ECS Fargate task definition
â”œâ”€â”€ lim.chatbot.egg-info/           # Package metadata
â”œâ”€â”€ LICENSE                         # License file
â”œâ”€â”€ README.md                       # This file
â”œâ”€â”€ pyproject.toml                  # Project configuration
â”œâ”€â”€ requirements.txt                # Python dependencies
â””â”€â”€ uv.lock                         # UV package manager lock file
```

---

## ğŸš€ Getting Started (Local)

### Prerequisites

- **Python 3.10+**
- **Docker** (for containerization)
- **MongoDB Atlas** (cloud) or local MongoDB instance
- **Google Gemini API Key** â€“ Get it from [Google Cloud Console](https://console.cloud.google.com/)
- **AWS Account** (for deployment)

### Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/End-to-End-LLM-ChatBot.git
   cd End-to-End-LLM-ChatBot
   ```

2. **Create a virtual environment**
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Setup environment variables**

   Create a `.env` file (copy from `.env.example`):
   ```bash
   cp .env.example .env
   ```

   Edit `.env` with your credentials:
   ```
   # MongoDB Configuration
   MONGO_URI=mongodb+srv://<username>:<password>@cluster.mongodb.net/
   MONGO_DB_NAME=Chatbot_DB
   MONGO_COLLECTION=Chatbot_History

   # Google Gemini Configuration
   GOOGLE_API_KEY=your-google-gemini-api-key

   # LangChain Configuration
   LANGCHAIN_API_KEY=your-langchain-api-key
   LANGCHAIN_PROJECT=chatbot
   ```

5. **Run FastAPI backend locally**
   ```bash
   uvicorn app.api.fastapi_app:app --reload --port 8000
   ```

   API documentation available at: [http://localhost:8000/docs](http://localhost:8000/docs)

6. **Run Streamlit frontend** (in a new terminal)
   ```bash
   cd frontend
   streamlit run chatbot_app.py
   ```

   Access UI at: [http://localhost:8501](http://localhost:8501)

---

## ğŸ³ Backend Deployment (AWS ECS)

### Step 1: Build Docker Image

```bash
docker build -t fastapi_chatbot .
```

### Step 2: Push to Amazon ECR

```bash
# Get login token
aws ecr get-login-password --region ap-south-1 | docker login --username AWS --password-stdin <account-id>.dkr.ecr.ap-south-1.amazonaws.com

# Tag image
docker tag fastapi_chatbot:latest <account-id>.dkr.ecr.ap-south-1.amazonaws.com/fastapi-chatbot:latest

# Push to ECR
docker push <account-id>.dkr.ecr.ap-south-1.amazonaws.com/fastapi-chatbot:latest
```

### Step 3: Store Environment Variables in AWS Systems Manager Parameter Store

```bash
aws ssm put-parameter \
  --name "/chatbot/MONGO_URI" \
  --value "mongodb+srv://..." \
  --type "SecureString" \
  --region ap-south-1

aws ssm put-parameter \
  --name "/chatbot/GOOGLE_API_KEY" \
  --value "your-api-key" \
  --type "SecureString" \
  --region ap-south-1

aws ssm put-parameter \
  --name "/chatbot/LANGCHAIN_API_KEY" \
  --value "your-langchain-key" \
  --type "SecureString" \
  --region ap-south-1
```

### Step 4: Register ECS Task Definition

```bash
aws ecs register-task-definition \
  --cli-input-json file://ecs-task-def.json \
  --region ap-south-1
```

### Step 5: Create ECS Service

```bash
aws ecs create-service \
  --cluster chatbot-cluster \
  --service-name chatbot-service \
  --task-definition fastapi-task:1 \
  --desired-count 1 \
  --launch-type FARGATE \
  --network-configuration "awsvpcConfiguration={subnets=[subnet-xxx],securityGroups=[sg-xxx],assignPublicIp=ENABLED}" \
  --region ap-south-1
```

---

## ğŸŒ Frontend Deployment (Render)

### Step 1: Connect Repository to Render

- Go to [https://render.com](https://render.com) â†’ **Create New** â†’ **Web Service**
- Connect your GitHub repository

### Step 2: Configure Build & Start Commands

**Build Command:**
```bash
pip install -r frontend/requirements.txt
```

**Start Command:**
```bash
streamlit run frontend/chatbot_app.py --server.port 10000 --server.address 0.0.0.0
```

### Step 3: Add Environment Variables

In Render dashboard, add:

| Variable | Value |
|----------|-------|
| `API_URL` | `https://your-ecs-endpoint/chat` |

### Step 4: Deploy

Click **Deploy** and wait for the service to go live! ğŸš€

Your frontend is now live on Render, communicating with your AWS ECS backend.

---

## ğŸ”„ CI/CD (GitHub Actions)

The workflow in `.github/workflows/deploy.yaml` automatically:

1. Builds the Docker image
2. Pushes to Amazon ECR
3. Updates the ECS task definition
4. Deploys the latest version to ECS

### Required GitHub Secrets

Add these secrets to your GitHub repository (Settings â†’ Secrets â†’ Actions):

| Secret | Description | Example |
|--------|-------------|---------|
| `AWS_ACCESS_KEY_ID` | AWS IAM access key | `AKIAIOSFODNN7EXAMPLE` |
| `AWS_SECRET_ACCESS_KEY` | AWS IAM secret key | `wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY` |
| `AWS_REGION` | AWS deployment region | `ap-south-1` |
| `ECR_REPOSITORY` | ECR repository name | `fastapi-chatbot` |
| `ECS_CLUSTER` | ECS cluster name | `chatbot-cluster` |
| `ECS_SERVICE` | ECS service name | `chatbot-service` |
| `CONTAINER_NAME` | ECS container name | `fastapi-container` |

---

## ğŸ“š API Documentation

### Base URL
```
http://localhost:8000  (local)
https://your-ecs-endpoint  (production)
```

### Endpoints

#### 1. Health Check
```http
GET /
```

**Response:**
```json
{
  "status": "healthy",
  "message": "FastAPI Chatbot Backend is running"
}
```

#### 2. Chat Endpoint
```http
POST /chat
```

**Request Body:**
```json
{
  "user_id": "user_123",
  "message": "What is LangChain?",
  "session_id": "session_456"
}
```

**Response:**
```json
{
  "user_id": "user_123",
  "session_id": "session_456",
  "user_message": "What is LangChain?",
  "assistant_response": "LangChain is a framework for building applications powered by large language models.",
  "timestamp": "2025-11-09T14:30:00Z"
}
```

---

## âš™ï¸ Configuration Reference

### Environment Variables

| Variable | Description | Required | Example |
|----------|-------------|----------|---------|
| `MONGO_URI` | MongoDB connection string | âœ… | `mongodb+srv://user:pass@cluster.mongodb.net/` |
| `MONGO_DB_NAME` | MongoDB database name | âœ… | `Chatbot_DB` |
| `MONGO_COLLECTION` | MongoDB collection name | âœ… | `Chatbot_History` |
| `GOOGLE_API_KEY` | Google Gemini API key | âœ… | `AIzaSy...` |
| `LANGCHAIN_API_KEY` | LangChain API key | âŒ | `ls__...` |
| `LANGCHAIN_PROJECT` | LangChain project name | âŒ | `chatbot` |

### Configuration File (`config/params.yaml`)

```yaml
chatbot:
  model: "gemini-pro"
  temperature: 0.7
  max_tokens: 512
  
mongo:
  timeout: 30
  retry_attempts: 3
  
logging:
  level: "INFO"
  format: "structured"
```

---

## ğŸ§  Example Prompt Flow

```
User: What is LangChain?
Assistant: LangChain is a framework for building applications powered by 
large language models. It provides tools and abstractions for working with LLMs.

User: Explain it like I'm 10 years old.
Assistant: Imagine a super smart robot that can read, understand, and write. 
LangChain is the toolbox that helps people build that robot!

User: Can you show me an example?
Assistant: Sure! Here's a simple example using Python:
```python
from langchain import OpenAI, PromptTemplate

llm = OpenAI(temperature=0.9)
prompt = PromptTemplate(input_variables=["topic"], template="Tell me about {topic}")
result = llm(prompt.format(topic="Python"))
print(result)
```

---

## ğŸ› ï¸ Development & Testing

### Run Smoke Tests

```bash
pytest tests/smoke_test_chat.py -v
```

### View Logs Locally

```bash
tail -f logs/app.log
```

### AWS CloudWatch Logs (Production)

```bash
aws logs tail /ecs/fastapi-chatbot --follow --region ap-south-1
```

---

## ğŸ“ Troubleshooting

### Issue: MongoDB Connection Error
- âœ… Verify `MONGO_URI` format is correct
- âœ… Check IP whitelist in MongoDB Atlas
- âœ… Ensure credentials are URL-encoded

### Issue: Gemini API Rate Limit
- âœ… Add request retry logic
- âœ… Implement exponential backoff
- âœ… Monitor API usage in Google Cloud Console

### Issue: ECS Task Failing
- âœ… Check CloudWatch logs: `aws logs tail /ecs/fastapi-chatbot`
- âœ… Verify IAM permissions for SSM Parameter Store
- âœ… Confirm security group rules allow egress

---

## ğŸ‘¨â€ğŸ’» Author

**Your Name / GenAI Learner**

- ğŸš€ **GitHub:** [@yourusername](https://github.com/yourusername)
- ğŸ’¼ **LinkedIn:** [Your Profile](https://linkedin.com/in/yourprofile)
- ğŸŒ **Portfolio:** [yourwebsite.com](https://yourwebsite.com)

---

## ğŸ“Š Project Status

- âœ… FastAPI + Async MongoDB backend
- âœ… Streamlit frontend
- âœ… AWS ECS backend deployment
- âœ… Render frontend deployment
- âœ… CI/CD GitHub Actions pipeline
- ğŸ”„ Authentication system (in progress)
- â³ HTTPS + Custom domain
- â³ Load balancing with ALB
- â³ Multi-region deployment

---

## ğŸ“œ License

This project is licensed under the **MIT License** â€“ see the [LICENSE](LICENSE) file for details.

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

<div align="center">

**â­ If this project helped you, please star it! â­**

Made with â¤ï¸ by GenAI Learner

</div>